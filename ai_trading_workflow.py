import os
import sys
import time
import importlib.util
import tempfile
import json
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any

# å¯¼å…¥æˆ‘ä»¬åˆ›å»ºçš„æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'src'))
from src.core.data_reader import DataReader
from src.core.backtester import Backtest, Strategy
from src.core.backtest_analyzer import BacktestAnalyzer
from src.utils.ai_strategy_generator import AIStrategyGenerator

class AITradingWorkflow:
    """
    AIäº¤æ˜“ç­–ç•¥å·¥ä½œæµï¼Œä¸²è”æ•°æ®è¯»å–ã€ç­–ç•¥ç”Ÿæˆã€å›æµ‹å’Œä¼˜åŒ–è¿‡ç¨‹
    ç²¾ç®€ç‰ˆï¼šä¿ç•™å¤šæ–‡ä»¶è¾“å…¥åŠŸèƒ½ï¼Œå°†å…·ä½“å¤„ç†äº¤ç»™å¤§æ¨¡å‹
    """
    
    def __init__(self, config: Optional[Dict] = None, config_file: Optional[str] = None):
        """
        åˆå§‹åŒ–å·¥ä½œæµ
        
        Args:
            config: å·¥ä½œæµé…ç½®å‚æ•°å­—å…¸
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰
        """
        # é»˜è®¤é…ç½®
        default_config = {
            'main_data_file': 'BINANCE_BTCUSDT_1D.csv',  # ä¸»å›æµ‹æ•°æ®æ–‡ä»¶
            'main_data_description': 'æ¯”ç‰¹å¸æ—¥çº¿æ•°æ®',  # ä¸»æ•°æ®æè¿°
            'additional_data_files': [],  # é¢å¤–æ•°æ®æ–‡ä»¶åˆ—è¡¨
            'additional_data_descriptions': [],  # é¢å¤–æ•°æ®æè¿°åˆ—è¡¨
            'initial_capital': 10000.0,  # åˆå§‹èµ„é‡‘
            'commission_rate': 0.001,  # ä½£é‡‘ç‡
            'max_optimization_rounds': 3,  # æœ€å¤§ä¼˜åŒ–è½®æ•°
            'use_reasoning': True,  # ä½¿ç”¨æ€è€ƒæ¨¡å¼
            'api_key': None,  # DeepSeek APIå¯†é’¥
            'output_dir': f'output_{datetime.now().strftime("%Y%m%d_%H%M%S")}',  # è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
            'data_directory': '',  # æ•°æ®æ–‡ä»¶ç›®å½•
            'run_all_steps': True,  # æ˜¯å¦è¿è¡Œæ‰€æœ‰æ­¥éª¤
            'steps_to_run': ['load_data', 'analyze_data', 'generate_initial_strategy', 'run_optimization_cycle']  # è¦è¿è¡Œçš„æ­¥éª¤åˆ—è¡¨
        }
        
        # åˆå¹¶é…ç½®
        self.config = default_config.copy()
        
        # 1. ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®ï¼ˆå¦‚æœæä¾›ï¼‰
        if config_file:
            file_config = self._load_config_file(config_file)
            if file_config:
                print(f"[é…ç½®] ä»é…ç½®æ–‡ä»¶ {config_file} åŠ è½½é…ç½®")
                # å¿½ç•¥ä¸å†ä½¿ç”¨çš„é…ç½®é¡¹
                # if 'correlation_analysis' in file_config:
                #     print("[é…ç½®] æ³¨æ„: correlation_analysisé…ç½®é¡¹å·²ä¸å†ä½¿ç”¨")
                #     file_config.pop('correlation_analysis')
                self.config.update(file_config)
        
        # 2. ä»ä¼ å…¥çš„å­—å…¸æ›´æ–°é…ç½®ï¼ˆä¼˜å…ˆçº§é«˜äºæ–‡ä»¶é…ç½®ï¼‰
        if config:
            print("[é…ç½®] ä»ä¼ å…¥çš„é…ç½®å­—å…¸æ›´æ–°é…ç½®")
            self.config.update(config)
        
        # ä¸å†éœ€è¦å¤„ç†æ—§é…ç½®çš„å‘åå…¼å®¹æ€§
        
        # 4. åŠ è½½APIå¯†é’¥
        self._load_api_key()
        
        # 5. éªŒè¯å¿…éœ€çš„é…ç½®é¡¹
        self._validate_config()
        
        # 6. æ ‡å‡†åŒ–é…ç½®é¡¹
        self._normalize_config()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir = self.config['output_dir']
        os.makedirs(self.output_dir, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.log_file = os.path.join(self.output_dir, f"workflow_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
        
        # å·¥ä½œæµçŠ¶æ€
        self.data = None  # å•ä¸€æ•°æ®é›†ï¼Œç”¨äºå›æµ‹
        self.data_sets = {}  # å¤šæ•°æ®é›†å­—å…¸
        self.analysis_result = None
        self.current_strategy_code = None
        self.current_strategy_description = None
        self.backtest_results = []
        self.optimization_history = []
        
        # åˆå§‹åŒ–æ•°æ®è¯»å–å™¨å’ŒAIç”Ÿæˆå™¨
        self.reader = DataReader(data_dir=self.config.get('data_directory', ''))
        self.generator = AIStrategyGenerator(
            api_key=self.config['api_key'],
            use_reasoning=self.config['use_reasoning']
        )
        
        # è®°å½•æ—¥å¿—
        self._log("å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ")
    
    def _log(self, message: str):
        """
        è®°å½•æ—¥å¿—
        
        Args:
            message: æ—¥å¿—æ¶ˆæ¯
        """
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(log_message + '\n')
        except Exception as e:
            # å¦‚æœæ— æ³•å†™å…¥æ—¥å¿—æ–‡ä»¶ï¼Œåªæ‰“å°åˆ°æ§åˆ¶å°
            print(f"æ— æ³•å†™å…¥æ—¥å¿—æ–‡ä»¶: {e}")
    
    def _load_config_file(self, config_file: str) -> Optional[Dict]:
        """
        ä»æ–‡ä»¶åŠ è½½é…ç½®
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŠ è½½çš„é…ç½®å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºå½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
            if not os.path.isabs(config_file):
                config_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), config_file)
            
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–é…ç½®æ–‡ä»¶ {config_file}: {e}")
            return None
    
    def _load_api_key(self):
        """
        åŠ è½½APIå¯†é’¥ï¼Œæ”¯æŒå¤šç§æ–¹å¼
        """
        if not self.config['api_key']:
            try:
                # 1. å°è¯•ä»configç›®å½•è¯»å–APIå¯†é’¥
                api_key_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config', 'api_key.json')
                if os.path.exists(api_key_path):
                    with open(api_key_path, 'r', encoding='utf-8') as f:
                        key_config = json.load(f)
                        # æ”¯æŒå¤šç§å¯èƒ½çš„é”®å
                        self.config['api_key'] = key_config.get('deepseek_api_key') or \
                                              key_config.get('deepseek') or \
                                              key_config.get('api_key')
                
                # 2. å¦‚æœé…ç½®ä¸­æŒ‡å®šäº†APIå¯†é’¥æ–‡ä»¶ï¼Œå°è¯•ä»é‚£é‡Œè¯»å–
                elif 'api_key_file' in self.config:
                    key_file = self.config['api_key_file']
                    if not os.path.isabs(key_file):
                        key_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), key_file)
                    if os.path.exists(key_file):
                        with open(key_file, 'r', encoding='utf-8') as f:
                            key_config = json.load(f)
                            self.config['api_key'] = key_config.get('deepseek_api_key') or \
                                                  key_config.get('deepseek') or \
                                                  key_config.get('api_key')
            except (FileNotFoundError, json.JSONDecodeError) as e:
                self._log(f"è­¦å‘Š: æ— æ³•è¯»å–APIå¯†é’¥æ–‡ä»¶: {e}")
    
    def _validate_config(self):
        """
        éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§
        """
        # ç¡®ä¿é¢å¤–æ•°æ®æè¿°ä¸é¢å¤–æ•°æ®æ–‡ä»¶æ•°é‡ä¸€è‡´
        if len(self.config.get('additional_data_files', [])) != len(self.config.get('additional_data_descriptions', [])):
            self._log("è­¦å‘Š: é¢å¤–æ•°æ®æè¿°æ•°é‡ä¸é¢å¤–æ•°æ®æ–‡ä»¶æ•°é‡ä¸ä¸€è‡´ï¼Œè‡ªåŠ¨è¡¥å……æè¿°")
            descriptions = self.config.get('additional_data_descriptions', [])
            while len(descriptions) < len(self.config.get('additional_data_files', [])):
                descriptions.append(f"é¢å¤–æ•°æ®é›†_{len(descriptions) + 1}")
            self.config['additional_data_descriptions'] = descriptions[:len(self.config.get('additional_data_files', []))]
    
    def _normalize_config(self):
        """
        æ ‡å‡†åŒ–é…ç½®é¡¹
        """
        # æ ‡å‡†åŒ–è¾“å‡ºç›®å½•è·¯å¾„
        if not os.path.isabs(self.config['output_dir']):
            self.config['output_dir'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), self.config['output_dir'])
        
        # æ ‡å‡†åŒ–æ•°æ®ç›®å½•è·¯å¾„
        if self.config.get('data_directory') and not os.path.isabs(self.config['data_directory']):
            self.config['data_directory'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), self.config['data_directory'])
        
        # ç¡®ä¿steps_to_runæ˜¯åˆ—è¡¨
        if isinstance(self.config.get('steps_to_run'), str):
            self.config['steps_to_run'] = [step.strip() for step in self.config['steps_to_run'].split(',')]
    
    def load_data(self) -> bool:
        """
        åŠ è½½å’Œå‡†å¤‡æ•°æ®ï¼Œæ”¯æŒä¸»æ•°æ®é›†å’Œé¢å¤–æ•°æ®é›†
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # åŠ è½½ä¸»å›æµ‹æ•°æ®é›†
            main_data_file = self.config['main_data_file']
            main_data_description = self.config['main_data_description']
            
            self._log(f"å¼€å§‹åŠ è½½ä¸»å›æµ‹æ•°æ®é›†: {main_data_file} ({main_data_description})")
            
            # è¯»å–ä¸»æ•°æ®é›†
            df = self.reader.read_csv_file(main_data_file)
            
            # å‡†å¤‡æ•°æ®
            df = self.reader.prepare_data(df)
            
            # å­˜å‚¨ä¸»æ•°æ®é›†
            main_symbol = main_data_file.split('.')[0].strip()  # æå–è‚¡ç¥¨/åŠ å¯†è´§å¸ä»£ç 
            self.data_sets[main_symbol] = {
                'data': df,
                'file': main_data_file,
                'description': main_data_description
            }
            
            self._log(f"  - ä¸»æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
            self._log(f"  - æ•°æ®æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
            
            # è®¾ç½®å›æµ‹æ•°æ®é›†ä¸ºä¸»æ•°æ®é›†
            self.data = df
            
            # åŠ è½½é¢å¤–æ•°æ®é›†
            additional_data_files = self.config.get('additional_data_files', [])
            additional_data_descriptions = self.config.get('additional_data_descriptions', [])
            
            if additional_data_files:
                self._log(f"å¼€å§‹åŠ è½½ {len(additional_data_files)} ä¸ªé¢å¤–æ•°æ®é›†")
                
                # ç¡®ä¿æè¿°åˆ—è¡¨ä¸æ–‡ä»¶åˆ—è¡¨é•¿åº¦ä¸€è‡´
                if len(additional_data_descriptions) < len(additional_data_files):
                    # ç”¨æ–‡ä»¶åå¡«å……ç¼ºå°‘çš„æè¿°
                    for i in range(len(additional_data_descriptions), len(additional_data_files)):
                        additional_data_descriptions.append(f"é¢å¤–æ•°æ®é›† {i+1}")
                    self.config['additional_data_descriptions'] = additional_data_descriptions
                
                # è¯»å–æ‰€æœ‰é¢å¤–æ•°æ®é›†
                for i, (data_file, data_desc) in enumerate(zip(additional_data_files, additional_data_descriptions)):
                    self._log(f"åŠ è½½é¢å¤–æ•°æ®æ–‡ä»¶ {i+1}/{len(additional_data_files)}: {data_file} ({data_desc})")
                    
                    # è¯»å–æ•°æ®
                    df = self.reader.read_csv_file(data_file)
                    
                    # å‡†å¤‡æ•°æ®
                    df = self.reader.prepare_data(df)
                    
                    # å­˜å‚¨é¢å¤–æ•°æ®é›†
                    symbol = data_file.split('.')[0].strip()  # æå–è‚¡ç¥¨/åŠ å¯†è´§å¸ä»£ç 
                    # é¿å…ä¸ä¸»æ•°æ®é›†å†²çª
                    if symbol in self.data_sets:
                        symbol = f"{symbol}_additional_{i}"
                    
                    self.data_sets[symbol] = {
                        'data': df,
                        'file': data_file,
                        'description': data_desc
                    }
                    
                    self._log(f"  - åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
                    self._log(f"  - æ•°æ®æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
            
            # ä¿å­˜æ•°æ®æ‘˜è¦
            self._save_data_summaries()
            
            return True
        except Exception as e:
            self._log(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
            
    def _save_data_summaries(self):
        """
        ä¿å­˜æ‰€æœ‰æ•°æ®é›†çš„æ‘˜è¦ä¿¡æ¯
        """
        summary_file = os.path.join(self.output_dir, 'data_summary.txt')
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"æ•°æ®é›†æ‘˜è¦ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for symbol, dataset in self.data_sets.items():
                f.write(f"## {symbol}: {dataset['description']}\n")
                f.write(f"æ–‡ä»¶: {dataset['file']}\n")
                f.write(f"è®°å½•æ•°: {len(dataset['data'])} æ¡\n")
                f.write(f"æ—¶é—´èŒƒå›´: {dataset['data'].index[0]} åˆ° {dataset['data'].index[-1]}\n")
                
                # æ·»åŠ æ•°æ®æ‘˜è¦
                data_summary = self.reader.get_data_summary(dataset['data'])
                f.write("\n" + data_summary + "\n\n")
                f.write("-" * 50 + "\n\n")
        
        self._log(f"æ•°æ®æ‘˜è¦å·²ä¿å­˜åˆ° {summary_file}")
    
    def analyze_data(self) -> bool:
        """
        ä½¿ç”¨AIåˆ†ææ•°æ®ï¼Œæ”¯æŒå¤šæ•°æ®é›†ä¿¡æ¯æ±‡æ€»
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if not self.data_sets:
                self._log("é”™è¯¯: æ•°æ®å°šæœªåŠ è½½")
                return False
            
            # é¦–å…ˆè¿›è¡Œå•ä¸€æ•°æ®é›†åˆ†æï¼ˆä½¿ç”¨é»˜è®¤å›æµ‹æ•°æ®é›†ï¼‰
            self._log("å¼€å§‹ä½¿ç”¨AIåˆ†æé»˜è®¤æ•°æ®é›†...")
            self.analysis_result = self.generator.analyze_data(
                self.data,
                self.config['main_data_description']
            )
            
            # ä¿å­˜å•ä¸€æ•°æ®é›†åˆ†æç»“æœ
            analysis_file = os.path.join(self.output_dir, 'data_analysis_result.txt')
            with open(analysis_file, 'w', encoding='utf-8') as f:
                f.write(f"æ•°æ®åˆ†æç»“æœ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(self.analysis_result)
            
            # ä¿å­˜æ•´ä½“æ•°æ®æ‘˜è¦
            all_summaries = """
æ•°æ®æ±‡æ€»ä¿¡æ¯ - """ + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n\n"
            for symbol, dataset in self.data_sets.items():
                all_summaries += f"\n=== {symbol} æ•°æ®é›†ä¿¡æ¯ ===\n"
                all_summaries += f"æ–‡ä»¶: {dataset['file']}\n"
                all_summaries += f"æè¿°: {dataset['description']}\n"
                all_summaries += f"æ•°æ®ç‚¹æ•°é‡: {len(dataset['data'])} æ¡\n"
                all_summaries += f"æ—¶é—´èŒƒå›´: {dataset['data'].index.min()} åˆ° {dataset['data'].index.max()}\n\n"
            
            summary_path = os.path.join(self.output_dir, "data_summary.txt")
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(all_summaries)
            
            # å¦‚æœæœ‰å¤šä¸ªæ•°æ®é›†ï¼Œåˆ›å»ºå¤šæ•°æ®é›†ä¿¡æ¯æ±‡æ€»
            if len(self.data_sets) > 1:
                self._log("ç”Ÿæˆå¤šæ•°æ®é›†ä¿¡æ¯æ±‡æ€»...")
                multi_data_summary = self._generate_multi_data_summary()
                
                # ä¿å­˜å¤šæ•°æ®é›†ä¿¡æ¯
                multi_data_file = os.path.join(self.output_dir, 'multi_data_summary.txt')
                with open(multi_data_file, 'w', encoding='utf-8') as f:
                    f.write(f"å¤šæ•°æ®é›†ä¿¡æ¯æ±‡æ€» - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                    f.write(multi_data_summary)
            
            self._log("æ•°æ®AIåˆ†æå®Œæˆ")
            return True
        except Exception as e:
            self._log(f"æ•°æ®åˆ†æå¤±è´¥: {e}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
    
    def _generate_multi_data_summary(self) -> str:
        """
        ç”Ÿæˆå¤šæ•°æ®é›†ä¿¡æ¯æ±‡æ€»
        
        Returns:
            str: å¤šæ•°æ®é›†ä¿¡æ¯æ±‡æ€»æ–‡æœ¬
        """
        # å‡†å¤‡æ‰€æœ‰æ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯
        symbols = list(self.data_sets.keys())
        
        result = []
        result.append("å¤šæ•°æ®é›†ä¿¡æ¯æ±‡æ€»")
        result.append(f"å‚ä¸åˆ†æçš„æ•°æ®é›†æ•°é‡: {len(symbols)}")
        result.append(f"å‚ä¸åˆ†æçš„æ•°æ®é›†: {', '.join(symbols)}")
        result.append("")
        
        # æ”¶é›†æ¯ä¸ªæ•°æ®é›†çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        for symbol, dataset in self.data_sets.items():
            result.append(f"\n{symbol} æ•°æ®é›†è¯¦æƒ…:")
            result.append(f"  - æè¿°: {dataset['description']}")
            result.append(f"  - æ–‡ä»¶: {dataset['file']}")
            result.append(f"  - æ•°æ®ç‚¹æ•°é‡: {len(dataset['data'])}")
            result.append(f"  - æ—¶é—´èŒƒå›´: {dataset['data'].index.min()} åˆ° {dataset['data'].index.max()}")
            
            # è®¡ç®—åŸºæœ¬ç»Ÿè®¡
            df = dataset['data']
            result.append(f"  - ä»·æ ¼èŒƒå›´: {df['close'].min():.2f} åˆ° {df['close'].max():.2f}")
            result.append(f"  - å¹³å‡äº¤æ˜“é‡: {df['volume'].mean():.2f}")
        
        return "\n".join(result)
    
    def generate_initial_strategy(self) -> bool:
        """
        ç”Ÿæˆåˆå§‹ç­–ç•¥
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if self.data is None:
                self._log("é”™è¯¯: æ•°æ®å°šæœªåŠ è½½")
                return False
            
            self._log("å¼€å§‹ç”Ÿæˆåˆå§‹äº¤æ˜“ç­–ç•¥...")
            
            # ç¡®ä¿åˆ†æç»“æœæœ‰æ•ˆ
            analysis_result = self.analysis_result if hasattr(self, 'analysis_result') and self.analysis_result else "æš‚æ— è¯¦ç»†åˆ†æ"
            
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
            current_dir = os.path.dirname(os.path.abspath(__file__))
            
            # æ·»åŠ è·¯å¾„æç¤ºåˆ°analysis_resultï¼Œç¡®ä¿ç”Ÿæˆçš„ç­–ç•¥æœ‰æ­£ç¡®çš„å¯¼å…¥è·¯å¾„
            path_hint = f"\n\né‡è¦æç¤º: ç”Ÿæˆçš„ç­–ç•¥ä»£ç å¿…é¡»åŒ…å«ä»¥ä¸‹å¯¼å…¥è®¾ç½®ï¼Œä»¥ç¡®ä¿æ­£ç¡®æ‰¾åˆ°backtesteræ¨¡å—ï¼š\n\n```python\nimport sys\nimport os\n# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œsrcç›®å½•åˆ°Pythonè·¯å¾„\nsys.path.append('{current_dir}')\nsys.path.append(os.path.join('{current_dir}', 'src'))\n\n# æ­£ç¡®å¯¼å…¥Strategyç±»\nfrom src.core.backtester import Strategy\n```\n\nè¯·ç¡®ä¿åœ¨ç­–ç•¥ä»£ç çš„å¼€å¤´åŒ…å«è¿™äº›å¯¼å…¥è¯­å¥ã€‚"
            
            # å‡†å¤‡å¤šæ•°æ®é›†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            multi_data_info = ""
            if len(self.data_sets) > 1:
                multi_data_info = "\n\nå¯ç”¨çš„å¤šæ•°æ®é›†ä¿¡æ¯:\n"
                for symbol, dataset in self.data_sets.items():
                    multi_data_info += f"- {symbol}: {dataset['description']}ï¼ˆå·²åŠ è½½ï¼‰\n"
                multi_data_info += "\næ³¨æ„ï¼šé»˜è®¤å›æµ‹å°†ä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°æ®é›†ï¼Œä½†æ‚¨å¯ä»¥åœ¨ç­–ç•¥ä¸­å¼•ç”¨å…¶ä»–æ•°æ®é›†è¿›è¡Œå¤šèµ„äº§åˆ†æã€‚"
            
            self.current_strategy_code, self.current_strategy_description = self.generator.generate_strategy(
                self.data,
                self.config['main_data_description'],
                analysis_result + path_hint + multi_data_info
            )
            
            # éªŒè¯ç­–ç•¥ä»£ç 
            if not self.generator.validate_strategy_code(self.current_strategy_code):
                self._log("ç­–ç•¥ä»£ç éªŒè¯å¤±è´¥")
                # æä¾›ä¸€ä¸ªå¤‡ç”¨ç­–ç•¥ä½œä¸ºå®‰å…¨æªæ–½
                self.current_strategy_code = self._get_fallback_strategy()
                self.current_strategy_description = "å¤‡ç”¨åŸºç¡€ç­–ç•¥"
            
            # ä¿å­˜ç­–ç•¥
            strategy_file = os.path.join(self.output_dir, 'initial_strategy.py')
            self.generator.save_strategy(
                self.current_strategy_code,
                self.current_strategy_description,
                strategy_file
            )
            
            self._log("åˆå§‹ç­–ç•¥ç”Ÿæˆå®Œæˆ")
            return True
        except Exception as e:
            self._log(f"ç­–ç•¥ç”Ÿæˆå¤±è´¥: {e}")
            # è®¾ç½®ä¸€ä¸ªå¤‡ç”¨ç­–ç•¥
            self.current_strategy_code = self._get_fallback_strategy()
            self.current_strategy_description = "å¤‡ç”¨åŸºç¡€ç­–ç•¥"
            strategy_file = os.path.join(self.output_dir, 'initial_strategy.py')
            self.generator.save_strategy(
                self.current_strategy_code,
                self.current_strategy_description,
                strategy_file
            )
            return True
            
    def _get_fallback_strategy(self) -> str:
        """
        è·å–å¤‡ç”¨ç­–ç•¥ä»£ç 
        
        Returns:
            str: å¤‡ç”¨ç­–ç•¥ä»£ç 
        """
        # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        
        # æ„å»ºç­–ç•¥ä»£ç 
        strategy_code = f"""
import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œsrcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('{current_dir}')
sys.path.append(os.path.join('{current_dir}', 'src'))

# æ­£ç¡®å¯¼å…¥Strategyç±»
from src.core.backtester import Strategy
import pandas as pd
import numpy as np

class GeneratedStrategy(Strategy):
    def __init__(self):
        super().__init__()
        self.position_size = 0.1
    
    def initialize(self, data):
        # åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥å—dataå‚æ•°
        pass
    
    def on_bar(self, index, row, data):
        # on_baræ–¹æ³•ï¼Œæ¥å—indexã€rowå’Œdataä¸‰ä¸ªå‚æ•°ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆæ— äº¤æ˜“ä¿¡å·ï¼‰
        return ""
"""
        
        return strategy_code
    
    def backtest_strategy(self, strategy_code: str = None, round_num: int = 0) -> Dict:
        """
        å›æµ‹ç­–ç•¥
        
        Args:
            strategy_code: ç­–ç•¥ä»£ç ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰ç­–ç•¥
            round_num: ä¼˜åŒ–è½®æ•°
            
        Returns:
            Dict: å›æµ‹ç»“æœ
        """
        try:
            if self.data is None:
                self._log("é”™è¯¯: æ•°æ®å°šæœªåŠ è½½")
                return None
            
            # ä½¿ç”¨æŒ‡å®šçš„ç­–ç•¥ä»£ç æˆ–å½“å‰ç­–ç•¥ä»£ç 
            code_to_use = strategy_code or self.current_strategy_code
            if not code_to_use:
                self._log("é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„ç­–ç•¥ä»£ç ")
                return None
            
            self._log(f"å¼€å§‹å›æµ‹ç­–ç•¥ (è½®æ•°: {round_num})...")
            
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
            current_dir = os.path.dirname(os.path.abspath(__file__))
            
            # ç¡®ä¿ç­–ç•¥ä»£ç å¼€å¤´æœ‰æ­£ç¡®çš„å¯¼å…¥è¯­å¥
            # ç§»é™¤æ‰€æœ‰å¯èƒ½å­˜åœ¨çš„å¯¼å…¥è¯­å¥
            import re
            code_to_use = re.sub(r'import\s+sys\s+.*?(?=class|#|$)', '', code_to_use, flags=re.DOTALL)
            code_to_use = re.sub(r'from\s+backtester\s+import\s+Strategy[\s\S]*?(?=class|#|$)', '', code_to_use, flags=re.DOTALL)
            code_to_use = re.sub(r'from\s+src.core.backtester\s+import\s+Strategy[\s\S]*?(?=class|#|$)', '', code_to_use, flags=re.DOTALL)
            
            # æ·»åŠ æ­£ç¡®çš„å¯¼å…¥è¯­å¥åˆ°ä»£ç å¼€å¤´
            import_lines = f"import sys\nimport os\nimport numpy as np\nimport pandas as pd\n# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œsrcç›®å½•åˆ°Pythonè·¯å¾„\nsys.path.append('{current_dir}')\nsys.path.append(os.path.join('{current_dir}', 'src'))\n\n# æ­£ç¡®å¯¼å…¥Strategyç±»\nfrom src.core.backtester import Strategy\n\n"
            code_to_use = import_lines + code_to_use
            self._log("å·²ä¸ºç­–ç•¥ä»£ç æ·»åŠ æ­£ç¡®çš„å¯¼å…¥è¯­å¥")
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åŠ è½½ç­–ç•¥ç±»
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8') as temp_file:
                temp_file.write(code_to_use)
                temp_file_path = temp_file.name
            
            try:
                # ç¡®ä¿Pythonè·¯å¾„è®¾ç½®æ­£ç¡®
                sys.path.append(current_dir)
                sys.path.append(os.path.join(current_dir, 'src'))
                
                # åŠ¨æ€å¯¼å…¥ç­–ç•¥ç±»
                spec = importlib.util.spec_from_file_location("strategy_module", temp_file_path)
                strategy_module = importlib.util.module_from_spec(spec)
                # è®¾ç½®æ¨¡å—çš„__file__å’Œ__package__å±æ€§
                strategy_module.__file__ = temp_file_path
                strategy_module.__package__ = "strategy_module"
                # å°†æ¨¡å—æ·»åŠ åˆ°sys.modulesä¸­
                sys.modules["strategy_module"] = strategy_module
                
                # æ‰§è¡Œæ¨¡å—
                try:
                    spec.loader.exec_module(strategy_module)
                except ImportError as e:
                    self._log(f"å¯¼å…¥é”™è¯¯: {e}")
                    self._log(f"å½“å‰Pythonè·¯å¾„: {sys.path}")
                    raise
                
                # è·å–ç­–ç•¥ç±»
                strategy_class = strategy_module.GeneratedStrategy
                
                # åˆ›å»ºç­–ç•¥å®ä¾‹
                strategy = strategy_class()
                
                # è¿è¡Œå›æµ‹
                backtest = Backtest(
                    self.data,
                    strategy,
                    initial_capital=self.config['initial_capital'],
                    commission_rate=self.config['commission_rate']
                )
                
                results = backtest.run()
                
                # è·å–å›æµ‹ç»“æœæ‘˜è¦
                summary = backtest.get_results_summary()
                
                # ä½¿ç”¨åˆ†æå™¨è¿›è¡Œæ›´è¯¦ç»†çš„åˆ†æ
                analyzer = BacktestAnalyzer(results)
                detailed_report = analyzer.generate_detailed_report()
                
                # ä¿å­˜å›æµ‹ç»“æœ
                backtest_dir = os.path.join(self.output_dir, f"backtest_round_{round_num}")
                os.makedirs(backtest_dir, exist_ok=True)
                
                # ä¿å­˜å›æµ‹æ‘˜è¦
                summary_file = os.path.join(backtest_dir, 'backtest_summary.txt')
                with open(summary_file, 'w', encoding='utf-8') as f:
                    f.write(summary)
                
                # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
                report_file = os.path.join(backtest_dir, 'detailed_analysis.txt')
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(detailed_report)
                
                # ä¿å­˜åˆ†ææŒ‡æ ‡JSON
                analyzer.to_json(os.path.join(backtest_dir, 'analysis_metrics.json'))
                
                # ä¿å­˜å›æµ‹ä½¿ç”¨çš„ç­–ç•¥ä»£ç 
                strategy_file = os.path.join(backtest_dir, 'strategy.py')
                with open(strategy_file, 'w', encoding='utf-8') as f:
                    f.write(code_to_use)
                
                # è®°å½•å›æµ‹ç»“æœ
                backtest_info = {
                    'round': round_num,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'total_return': results.get('total_return', 0),
                    'sharpe_ratio': results.get('sharpe_ratio', 0),
                    'max_drawdown': results.get('max_drawdown', 0),
                    'win_rate': results.get('win_rate', 0),
                    'dir': backtest_dir
                }
                
                self.backtest_results.append(backtest_info)
                
                self._log(f"å›æµ‹å®Œæˆï¼Œæ”¶ç›Šç‡: {backtest_info['total_return']:.2%}, å¤æ™®æ¯”ç‡: {backtest_info['sharpe_ratio']:.2f}")
                
                # è¿”å›å›æµ‹æ‘˜è¦ï¼ˆç”¨äºAIä¼˜åŒ–ï¼‰
                return {
                    'summary': summary,
                    'detailed_report': detailed_report,
                    'metrics': analyzer.calculate_comprehensive_metrics(),
                    'strategy_code': code_to_use
                }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_file_path):
                    os.unlink(temp_file_path)
                    
        except Exception as e:
            self._log(f"å›æµ‹å¤±è´¥: {e}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None
    
    def optimize_strategy(self, backtest_result: Dict, round_num: int) -> Tuple[str, str]:
        """
        ä¼˜åŒ–ç­–ç•¥
        
        Args:
            backtest_result: å›æµ‹ç»“æœ
            round_num: ä¼˜åŒ–è½®æ•°
            
        Returns:
            Tuple[str, str]: (ä¼˜åŒ–åçš„ç­–ç•¥ä»£ç , ä¼˜åŒ–åˆ†æ)
        """
        try:
            self._log(f"å¼€å§‹ä¼˜åŒ–ç­–ç•¥ (è½®æ•°: {round_num})...")
            
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
            current_dir = os.path.dirname(os.path.abspath(__file__))
            
            # æ·»åŠ è·¯å¾„æç¤ºåˆ°åˆ†æç»“æœï¼Œç¡®ä¿ç”Ÿæˆçš„ç­–ç•¥æœ‰æ­£ç¡®çš„å¯¼å…¥è·¯å¾„
            path_hint = f"\n\né‡è¦æç¤º: ä¼˜åŒ–åçš„ç­–ç•¥ä»£ç å¿…é¡»åŒ…å«ä»¥ä¸‹å¯¼å…¥è®¾ç½®ï¼Œä»¥ç¡®ä¿æ­£ç¡®æ‰¾åˆ°backtesteræ¨¡å—ï¼š\n\n```python\nimport sys\nimport os\n# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œsrcç›®å½•åˆ°Pythonè·¯å¾„\nsys.path.append('{current_dir}')\nsys.path.append(os.path.join('{current_dir}', 'src'))\n\n# æ­£ç¡®å¯¼å…¥Strategyç±»\nfrom src.core.backtester import Strategy\n```\n\nè¯·ç¡®ä¿åœ¨ç­–ç•¥ä»£ç çš„å¼€å¤´åŒ…å«è¿™äº›å¯¼å…¥è¯­å¥ã€‚"
            
            # è°ƒç”¨AIä¼˜åŒ–ç­–ç•¥
            optimized_code, optimization_analysis = self.generator.optimize_strategy(
                strategy_code=backtest_result['strategy_code'],
                strategy_description=self.current_strategy_description,
                backtest_results=backtest_result['summary'] + path_hint,
                data_description=self.config['main_data_description']
            )
            
            # éªŒè¯ä¼˜åŒ–åçš„ç­–ç•¥ä»£ç 
            if not self.generator.validate_strategy_code(optimized_code):
                self._log("ä¼˜åŒ–åçš„ç­–ç•¥ä»£ç éªŒè¯å¤±è´¥")
                return None, None
            
            # ä¿å­˜ä¼˜åŒ–åˆ†æå’Œä»£ç 
            optimize_dir = os.path.join(self.output_dir, f"optimization_round_{round_num}")
            os.makedirs(optimize_dir, exist_ok=True)
            
            # ä¿å­˜ä¼˜åŒ–åˆ†æ
            analysis_file = os.path.join(optimize_dir, 'optimization_analysis.txt')
            with open(analysis_file, 'w', encoding='utf-8') as f:
                f.write(optimization_analysis)
            
            # ä¿å­˜ä¼˜åŒ–åçš„ç­–ç•¥ä»£ç 
            strategy_file = os.path.join(optimize_dir, 'optimized_strategy.py')
            with open(strategy_file, 'w', encoding='utf-8') as f:
                f.write(optimized_code)
            
            # è®°å½•ä¼˜åŒ–å†å²
            self.optimization_history.append({
                'round': round_num,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'dir': optimize_dir
            })
            
            self._log("ç­–ç•¥ä¼˜åŒ–å®Œæˆ")
            return optimized_code, optimization_analysis
            
        except Exception as e:
            self._log(f"ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            return None, None
    
    def run_optimization_cycle(self, max_rounds: int = None) -> bool:
        """
        è¿è¡Œä¼˜åŒ–å¾ªç¯
        
        Args:
            max_rounds: æœ€å¤§ä¼˜åŒ–è½®æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„å€¼
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            rounds = max_rounds or self.config['max_optimization_rounds']
            
            self._log(f"å¼€å§‹ä¼˜åŒ–å¾ªç¯ï¼Œå…± {rounds} è½®")
            
            # ç¬¬ä¸€è½®ï¼šå›æµ‹åˆå§‹ç­–ç•¥
            backtest_result = self.backtest_strategy(round_num=0)
            if not backtest_result:
                return False
            
            # ä¿å­˜ç¬¬ä¸€è½®ç»“æœ
            best_result = backtest_result
            best_code = self.current_strategy_code
            
            # è¿›è¡Œå¤šè½®ä¼˜åŒ–
            for i in range(1, rounds + 1):
                self._log(f"===== ä¼˜åŒ–è½®æ¬¡ {i}/{rounds} =====")
                
                # ä¼˜åŒ–ç­–ç•¥
                optimized_code, _ = self.optimize_strategy(
                    backtest_result=backtest_result,
                    round_num=i
                )
                
                if not optimized_code:
                    self._log(f"ç¬¬ {i} è½®ä¼˜åŒ–å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # å›æµ‹ä¼˜åŒ–åçš„ç­–ç•¥
                new_backtest_result = self.backtest_strategy(
                    strategy_code=optimized_code,
                    round_num=i
                )
                
                if not new_backtest_result:
                    self._log(f"ç¬¬ {i} è½®å›æµ‹å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # æ¯”è¾ƒç»“æœï¼Œæ›´æ–°æœ€ä¼˜ç»“æœ
                current_sharpe = new_backtest_result['metrics'].get('sharpe_ratio', 0)
                best_sharpe = best_result['metrics'].get('sharpe_ratio', 0)
                
                if current_sharpe > best_sharpe:
                    best_result = new_backtest_result
                    best_code = optimized_code
                    self._log(f"ç¬¬ {i} è½®ä¼˜åŒ–æˆåŠŸï¼Œå¤æ™®æ¯”ç‡ä» {best_sharpe:.2f} æå‡åˆ° {current_sharpe:.2f}")
                else:
                    self._log(f"ç¬¬ {i} è½®ä¼˜åŒ–æœªèƒ½æé«˜æ€§èƒ½ï¼Œä¿æŒå½“å‰æœ€ä¼˜ç­–ç•¥")
                
                # æ›´æ–°å›æµ‹ç»“æœç”¨äºä¸‹ä¸€è½®ä¼˜åŒ–
                backtest_result = new_backtest_result
                self.current_strategy_code = optimized_code
                
                # çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
                time.sleep(5)
            
            # ä¿å­˜æœ€ç»ˆæœ€ä¼˜ç­–ç•¥
            final_strategy_file = os.path.join(self.output_dir, 'final_optimized_strategy.py')
            with open(final_strategy_file, 'w', encoding='utf-8') as f:
                f.write(best_code)
            
            self._log(f"ä¼˜åŒ–å¾ªç¯å®Œæˆï¼Œæœ€ä¼˜ç­–ç•¥å·²ä¿å­˜åˆ° {final_strategy_file}")
            
            # ç”Ÿæˆä¼˜åŒ–æ€»ç»“æŠ¥å‘Š
            self._generate_optimization_summary()
            
            return True
            
        except Exception as e:
            self._log(f"ä¼˜åŒ–å¾ªç¯å¤±è´¥: {e}")
            return False
    
    def _generate_optimization_summary(self):
        """
        ç”Ÿæˆä¼˜åŒ–æ€»ç»“æŠ¥å‘Š
        """
        try:
            summary_file = os.path.join(self.output_dir, 'optimization_summary.txt')
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write("===== AIäº¤æ˜“ç­–ç•¥ä¼˜åŒ–æ€»ç»“æŠ¥å‘Š =====\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                # æ•°æ®ä¿¡æ¯
                f.write("## æ•°æ®ä¿¡æ¯\n")
                f.write(f"- ä¸»æ•°æ®æ–‡ä»¶: {self.config.get('main_data_file', 'æœªçŸ¥')}\n")
                f.write(f"- ä¸»æ•°æ®æè¿°: {self.config.get('main_data_description', 'æœªçŸ¥')}\n")
                if self.data is not None:
                    f.write(f"- æ•°æ®é‡: {len(self.data)} æ¡è®°å½•\n")
                    f.write(f"- æ—¶é—´èŒƒå›´: {self.data.index[0]} åˆ° {self.data.index[-1]}\n\n")
                
                # å¤šæ•°æ®é›†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                if len(self.data_sets) > 1:
                    f.write("## å¤šæ•°æ®é›†ä¿¡æ¯\n")
                    f.write(f"- ä½¿ç”¨çš„æ•°æ®é›†æ•°é‡: {len(self.data_sets)}\n")
                    for symbol, dataset in self.data_sets.items():
                        f.write(f"  - {symbol}: {dataset['description']}\n")
                    f.write("\n")
                
                # å›æµ‹ç»“æœå¯¹æ¯”
                if self.backtest_results:
                    f.write("## å›æµ‹ç»“æœå¯¹æ¯”\n")
                    f.write("è½®æ¬¡,æ—¶é—´,æ€»æ”¶ç›Šç‡,å¤æ™®æ¯”ç‡,æœ€å¤§å›æ’¤,èƒœç‡\n")
                    
                    for result in self.backtest_results:
                        f.write(f"{result['round']},")
                        f.write(f"{result['timestamp']},")
                        f.write(f"{result['total_return']:.2%},")
                        f.write(f"{result['sharpe_ratio']:.2f},")
                        f.write(f"{result['max_drawdown']:.2%},")
                        f.write(f"{result['win_rate']:.2%}\n")
                    
                    # æ ‡è®°æœ€ä¼˜ç»“æœ
                    if len(self.backtest_results) > 1:
                        best_result = max(self.backtest_results, key=lambda x: x['sharpe_ratio'])
                        f.write(f"\næœ€ä¼˜ç»“æœ (è½®æ¬¡ {best_result['round']}):\n")
                        f.write(f"- æ€»æ”¶ç›Šç‡: {best_result['total_return']:.2%}\n")
                        f.write(f"- å¤æ™®æ¯”ç‡: {best_result['sharpe_ratio']:.2f}\n")
                        f.write(f"- æœ€å¤§å›æ’¤: {best_result['max_drawdown']:.2%}\n")
                
                # ä¼˜åŒ–è¿‡ç¨‹
                f.write("\n## ä¼˜åŒ–è¿‡ç¨‹\n")
                f.write(f"- æ€»ä¼˜åŒ–è½®æ•°: {self.config['max_optimization_rounds']}\n")
                f.write(f"- æˆåŠŸä¼˜åŒ–è½®æ•°: {len(self.optimization_history)}\n\n")
                
                # ç»“è®ºå’Œå»ºè®®
                f.write("## ç»“è®ºä¸å»ºè®®\n")
                if self.backtest_results:
                    best_result = max(self.backtest_results, key=lambda x: x['sharpe_ratio'])
                    
                    if best_result['sharpe_ratio'] > 1.0 and best_result['total_return'] > 0:
                        f.write("âœ… ç­–ç•¥è¡¨ç°ä¼˜ç§€ï¼Œå»ºè®®è¿›ä¸€æ­¥éªŒè¯åè€ƒè™‘å®ç›˜æµ‹è¯•\n")
                    elif best_result['sharpe_ratio'] > 0.5 and best_result['total_return'] > 0:
                        f.write("âœ… ç­–ç•¥è¡¨ç°è‰¯å¥½ï¼Œå…·æœ‰ä¸€å®šçš„å®ç”¨æ€§\n")
                    elif best_result['total_return'] > 0:
                        f.write("âš ï¸  ç­–ç•¥èƒ½å¤Ÿç›ˆåˆ©ä½†é£é™©è¾ƒé«˜ï¼Œå»ºè®®åŠ å¼ºé£é™©æ§åˆ¶\n")
                    else:
                        f.write("âŒ ç­–ç•¥æœªèƒ½äº§ç”Ÿæ­£æ”¶ç›Šï¼Œå»ºè®®é‡æ–°è®¾è®¡\n")
                    
                    f.write("\nå»ºè®®:\n")
                    f.write("1. åœ¨ä¸åŒæ—¶é—´æ®µçš„æ•°æ®ä¸Šè¿›è¡ŒéªŒè¯\n")
                    f.write("2. è€ƒè™‘æ·»åŠ ä»“ä½ç®¡ç†å’Œæ­¢æŸç­–ç•¥\n")
                    f.write("3. ç›‘æ§å®ç›˜è¡¨ç°ï¼ŒåŠæ—¶è°ƒæ•´å‚æ•°\n")
            
            self._log(f"ä¼˜åŒ–æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ° {summary_file}")
            
        except Exception as e:
            self._log(f"ç”Ÿæˆä¼˜åŒ–æ€»ç»“å¤±è´¥: {e}")
    
    def run_full_workflow(self) -> bool:
        """
        è¿è¡Œå®Œæ•´çš„AIäº¤æ˜“ç­–ç•¥å·¥ä½œæµ
        æ ¹æ®é…ç½®é€‰æ‹©è¦è¿è¡Œçš„æ­¥éª¤
        
        Returns:
            bool: å·¥ä½œæµæ˜¯å¦æˆåŠŸè¿è¡Œ
        """
        try:
            self._log("ğŸš€ å¼€å§‹è¿è¡ŒAIäº¤æ˜“ç­–ç•¥å·¥ä½œæµ...")
            
            # æ‰“å°é…ç½®æ‘˜è¦
            self._log(f"é…ç½®æ‘˜è¦: ä¸»æ•°æ®æ–‡ä»¶={self.config.get('main_data_file', 'æœªçŸ¥')}, é¢å¤–æ•°æ®æ–‡ä»¶={len(self.config.get('additional_data_files', []))}ä¸ª, ä¼˜åŒ–è½®æ•°={self.config['max_optimization_rounds']}")
            
            # å®šä¹‰å·¥ä½œæµæ­¥éª¤æ˜ å°„
            workflow_steps = {
                'load_data': {
                    'method': self.load_data,
                    'description': 'åŠ è½½æ•°æ®'
                },
                'analyze_data': {
                    'method': self.analyze_data,
                    'description': 'åˆ†ææ•°æ®'
                },
                'generate_initial_strategy': {
                    'method': self.generate_initial_strategy,
                    'description': 'ç”Ÿæˆåˆå§‹ç­–ç•¥'
                },
                'run_optimization_cycle': {
                    'method': self.run_optimization_cycle,
                    'description': 'è¿è¡Œä¼˜åŒ–å¾ªç¯'
                }
            }
            
            # ç¡®å®šè¦è¿è¡Œçš„æ­¥éª¤
            steps_to_run = self.config.get('steps_to_run', [])
            if not steps_to_run or self.config.get('run_all_steps', True):
                # å¦‚æœæ²¡æœ‰æŒ‡å®šæ­¥éª¤æˆ–run_all_stepsä¸ºTrueï¼Œåˆ™è¿è¡Œæ‰€æœ‰æ­¥éª¤
                steps_to_run = list(workflow_steps.keys())
            
            # æŒ‰å®šä¹‰çš„é¡ºåºè¿è¡Œæ­¥éª¤
            ordered_steps = ['load_data', 'analyze_data', 'generate_initial_strategy', 'run_optimization_cycle']
            filtered_steps = [step for step in ordered_steps if step in steps_to_run]
            
            self._log(f"å°†æŒ‰ä»¥ä¸‹é¡ºåºè¿è¡Œæ­¥éª¤: {', '.join(filtered_steps)}")
            
            # æ‰§è¡Œæ¯ä¸ªæ­¥éª¤
            for step_name in filtered_steps:
                step_info = workflow_steps.get(step_name)
                if not step_info:
                    self._log(f"è­¦å‘Š: æœªçŸ¥æ­¥éª¤ '{step_name}'ï¼Œè·³è¿‡")
                    continue
                
                self._log(f"\nğŸ“Š å¼€å§‹ {step_info['description']}...")
                start_time = time.time()
                
                try:
                    success = step_info['method']()
                    
                    if not success:
                        self._log(f"âŒ {step_info['description']}å¤±è´¥")
                        # å¦‚æœæ­¥éª¤å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­å–å†³äºé…ç½®
                        if self.config.get('continue_on_failure', False):
                            self._log("é…ç½®å…è®¸ç»§ç»­æ‰§è¡Œï¼Œå°†å°è¯•è¿è¡Œä¸‹ä¸€ä¸ªæ­¥éª¤")
                        else:
                            return False
                    else:
                        duration = time.time() - start_time
                        self._log(f"âœ… {step_info['description']}æˆåŠŸå®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
                except Exception as e:
                    self._log(f"âŒ {step_info['description']}æ‰§è¡Œå¼‚å¸¸: {e}")
                    import traceback
                    self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                    if not self.config.get('continue_on_failure', False):
                        return False
            
            # ç”Ÿæˆæœ€ç»ˆçš„ä¼˜åŒ–æ€»ç»“æŠ¥å‘Š
            if 'run_optimization_cycle' in filtered_steps:
                self._generate_optimization_summary()
            
            self._log("ğŸ‰ AIäº¤æ˜“ç­–ç•¥å·¥ä½œæµè¿è¡Œå®Œæˆï¼")
            self._log(f"æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")
            return True
            
        except Exception as e:
            self._log(f"å·¥ä½œæµè¿è¡Œå¤±è´¥: {e}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False

def main():
    """
    ä¸»å‡½æ•°ï¼Œæ”¯æŒä»å‘½ä»¤è¡Œå‚æ•°è¯»å–é…ç½®æ–‡ä»¶è·¯å¾„
    
    ç”¨æ³•ç¤ºä¾‹:
        python ai_trading_workflow.py
        python ai_trading_workflow.py --config my_config.json
        python ai_trading_workflow.py --config /path/to/config.json
    """
    import argparse
    
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='AIäº¤æ˜“ç­–ç•¥å·¥ä½œæµ')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰')
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº†é…ç½®æ–‡ä»¶ï¼Œå°è¯•åŠ è½½
    config_file = args.config
    
    # åŸºç¡€é…ç½®ï¼ˆä¼˜å…ˆçº§ä½äºé…ç½®æ–‡ä»¶ï¼‰
    base_config = {
        # ç²¾ç®€ç‰ˆï¼šç§»é™¤äº†ä¸å¿…è¦çš„é…ç½®é¡¹
    }
    
    print("ğŸ¯ AIäº¤æ˜“ç­–ç•¥å·¥ä½œæµå¯åŠ¨")
    
    # åˆ›å»ºå¹¶è¿è¡Œå·¥ä½œæµ
    workflow = AITradingWorkflow(config=base_config, config_file=config_file)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œæ‰“å°æç¤ºä¿¡æ¯
    if not config_file:
        print("\nâ„¹ï¸  æœªæŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        print("   æ‚¨å¯ä»¥é€šè¿‡ --config å‚æ•°æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„")
        print("   ä¾‹å¦‚: python ai_trading_workflow.py --config my_config.json")
        print(f"\nğŸ“Š æ•°æ®æ–‡ä»¶: {workflow.config['main_data_file']}")
        print(f"ğŸ’° åˆå§‹èµ„é‡‘: {workflow.config['initial_capital']}")
        print(f"ğŸ”„ ä¼˜åŒ–è½®æ•°: {workflow.config['max_optimization_rounds']}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {workflow.output_dir}")
    else:
        print(f"\nğŸ“„ ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_file}")
        print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {workflow.config['main_data_file']}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {workflow.output_dir}")
    
    # è¿è¡Œå·¥ä½œæµ
    success = workflow.run_full_workflow()
    
    # æ‰“å°ç»“æœä¿¡æ¯
    if success:
        print(f"\nâœ… å·¥ä½œæµæˆåŠŸå®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {workflow.output_dir}")
        print("\nğŸ” ä¸‹ä¸€æ­¥å»ºè®®:")
        print("   1. æŸ¥çœ‹ä¼˜åŒ–æ€»ç»“æŠ¥å‘Šäº†è§£ç­–ç•¥è¡¨ç°")
        print("   2. æ£€æŸ¥ç”Ÿæˆçš„ç­–ç•¥ä»£ç æ˜¯å¦ç¬¦åˆé¢„æœŸ")
        print("   3. é€šè¿‡é…ç½®æ–‡ä»¶è‡ªå®šä¹‰æ›´å¤šå‚æ•°è¿›è¡Œå®éªŒ")
    else:
        print("\nâŒ å·¥ä½œæµè¿è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯")

if __name__ == "__main__":
    main()